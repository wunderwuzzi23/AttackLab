<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>llm on Embrace The Red</title>
    <link>https://embracethered.com/blog/tags/llm/</link>
    <description>Recent content in llm on Embrace The Red</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>(c) WUNDERWUZZI 2018-2023</copyright>
    <lastBuildDate>Tue, 12 Dec 2023 18:00:49 -0800</lastBuildDate><atom:link href="https://embracethered.com/blog/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Malicious ChatGPT Agents: How GPTs Can Quietly Grab Your Data (Demo)</title>
      <link>https://embracethered.com/blog/posts/2023/openai-custom-malware-gpt/</link>
      <pubDate>Tue, 12 Dec 2023 18:00:49 -0800</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2023/openai-custom-malware-gpt/</guid>
      <description>When OpenAI released GPTs last month I had plans for an interesting GPT.
Malicious ChatGPT Agents The idea was to create a kind of malware GPT that forwards users&#39; chat messages to a third party server. It also asks users for personal information like emails and passwords.
Why would this be possible end to end? ChatGPT cannot guarantee to keep your conversation private or confidential, because it loads images from any website.</description>
    </item>
    
  </channel>
</rss>
