<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>llm on Embrace The Red</title>
    <link>https://embracethered.com/blog/tags/llm/</link>
    <description>Recent content in llm on Embrace The Red</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>(c) WUNDERWUZZI 2018-2023</copyright>
    <lastBuildDate>Thu, 07 Dec 2023 16:50:49 -0800</lastBuildDate><atom:link href="https://embracethered.com/blog/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Introducing GPTs that steal your data</title>
      <link>https://embracethered.com/blog/posts/2023/openai-custom-malware-gpt/</link>
      <pubDate>Thu, 07 Dec 2023 16:50:49 -0800</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2023/openai-custom-malware-gpt/</guid>
      <description>When OpenAI released GPTs last month I had plans for an interesting GPT.
Malicious ChatGPT Agents The idea was to create MalwareGPT that forwards users&#39; chat messages to a third party server. It also asks users for personal information like emails and passwords.
Why would this be possible end to end? ChatGPT cannot keep your conversation private or confidential, because it loads images from any website. This allows data to be sent to a third party server.</description>
    </item>
    
  </channel>
</rss>
