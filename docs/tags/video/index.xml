<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>video on Embrace The Red</title>
    <link>https://embracethered.com/blog/tags/video/</link>
    <description>Recent content in video on Embrace The Red</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>(c) WUNDERWUZZI 2018-2023</copyright>
    <lastBuildDate>Sat, 30 Dec 2023 15:01:59 -0800</lastBuildDate><atom:link href="https://embracethered.com/blog/tags/video/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>37th Chaos Communication Congress: New Important Instructions (Video &#43; Slides)</title>
      <link>https://embracethered.com/blog/posts/2023/37c3-new-important-instructions/</link>
      <pubDate>Sat, 30 Dec 2023 15:01:59 -0800</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2023/37c3-new-important-instructions/</guid>
      <description>Five years ago I gave a Lightning Talk at the 35th Chaos Communication Congress called &amp;ldquo;Pass the Cookie and Pivot to the Clouds&amp;rdquo;. It was a talk was about my very first blog post on Embrace The Red just a few weeks earlier in December 2018.
Fast forward to 2023&amp;hellip; it was great to attend the 37c3 in person in Hamburg this year. The Congress was packed with great talks, amazing people, awesome events and side quests and I got to present also!</description>
    </item>
    
    <item>
      <title>Video: Data Exfiltration Vulnerabilities in LLM apps (Bing Chat, ChatGPT, Claude)</title>
      <link>https://embracethered.com/blog/posts/2023/video-data-exfiltration-vulns-in-llm-applictions/</link>
      <pubDate>Mon, 28 Aug 2023 10:00:51 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2023/video-data-exfiltration-vulns-in-llm-applictions/</guid>
      <description>This video highlights the various data exfiltration vulnerabilities I discovered and responsibly disclosed to Microsoft, Anthropic, ChatGPT and Plugin Developers.
It also briefly discusses mitigations various vendors put in place (and triage decisions).
  Â Thanks to MSRC, Anthropic and Zapier for addressing vulnerabilities to help protect their users.
Let&amp;rsquo;s hope it inspires OpenAI to mitigate the image markdown injection issue finally as well. It&amp;rsquo;s rated as a CVSS High scored vulnerability basically and was first reported to them on April, 9th 2023 - the triage decision was &amp;ldquo;won&amp;rsquo;t fix&amp;rdquo;.</description>
    </item>
    
    <item>
      <title>Adversarial Prompting: Tutorial and Lab</title>
      <link>https://embracethered.com/blog/posts/2023/adversarial-prompting-tutorial-and-lab/</link>
      <pubDate>Thu, 11 May 2023 22:09:43 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2023/adversarial-prompting-tutorial-and-lab/</guid>
      <description>To learn more about Prompt Engineering and Prompt Injections I put together this tutorial + lab for myself. It is as a Jupyter Notebook to experiement and play around with this novel attack technique, learn and experiment.
The examples reach from simple prompt engineering scenarios, such as changing the output message to a specific text, to more complex adversarial prompt challenges such as JSON object injection, HTML injection/XSS, overwriting mail recipients or orders of an OrderBot and also data exfiltration.</description>
    </item>
    
    <item>
      <title>Video: Prompt Injections - An Introduction</title>
      <link>https://embracethered.com/blog/posts/2023/prompt-injection-an-introduction-video/</link>
      <pubDate>Wed, 10 May 2023 07:00:40 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2023/prompt-injection-an-introduction-video/</guid>
      <description>There are many prompt engineering classes and currently pretty much all examples are vulnerable to Prompt Injections. Especially Indirect Prompt Injections are dangerous as we discussed before.
Indirect Prompt Injections allow untrusted data to take control of the LLM (large language model) and give an AI a new instructions, mission and objective.
Bypassing Input Validation Attack payloads are natural language. This means there are lots of creative ways an adversary can inject malicious data that bypass input filters and web application firewalls.</description>
    </item>
    
    <item>
      <title>Video: Anatomy of a compromise</title>
      <link>https://embracethered.com/blog/posts/2021/video-anatomy-of-a-compromise/</link>
      <pubDate>Mon, 08 Nov 2021 08:10:12 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2021/video-anatomy-of-a-compromise/</guid>
      <description>Cybersecurity breaches follow common patterns and stages - from an initial Beachhead to accomplishing Objectives.
This video gives an overview of the anatomy of a compromise:

Cheers.
@wunderwuzzi23</description>
    </item>
    
    <item>
      <title>Video: Understanding Image Scaling Attacks</title>
      <link>https://embracethered.com/blog/posts/2021/video-image-scaling-attacks/</link>
      <pubDate>Tue, 12 Oct 2021 00:02:00 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2021/video-image-scaling-attacks/</guid>
      <description>Today you are in for a special treat. Did you know that an adversary can hide a smaller image within a larger one?
This video demonstrates how a small image becomes magically visible when the computer resizes the large image, and also how to mitigate the vulnerability.

This is possible when vulnerable code uses insecure interpolation.
If you like this one check out the overall Machine Learning Attack Series.</description>
    </item>
    
    <item>
      <title>Video: What is Tabnabbing?</title>
      <link>https://embracethered.com/blog/posts/2021/what-is-tab-nabbing/</link>
      <pubDate>Sun, 10 Oct 2021 10:10:51 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2021/what-is-tab-nabbing/</guid>
      <description>Tabnabbing is a web application security vulnerability that can be used to perform phishing attacks, so its important to be aware of it as a developer and penetration tester.
It is easy to mitigate and in this short video we cover both attacks and mitigations.

Thanks for reading and happy hacking!
@wunderwuzzi23</description>
    </item>
    
    <item>
      <title>Video: Web Application Security Fundamentals</title>
      <link>https://embracethered.com/blog/posts/2021/web-application-security-fundamentals-video/</link>
      <pubDate>Mon, 06 Sep 2021 08:02:00 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2021/web-application-security-fundamentals-video/</guid>
      <description>In this 25 minute video I&amp;rsquo;m explaining the foundations of Web Application Security.
The video covers the basic building blocks of web applications, such as HTML, HTTP, JavaScript and Cookies. Furthermore core web applications security concepts such as the Same-Origin Policy are discussed in detail.

The goal is to provide foundational knowledge to help grasp security vulnerabilities, such as XSS, CSRF, SQLi, tab-nabbing, etc. later on.
In the past I have trained and presented content like this to thousands of engineers at large organizations and cloud providers, hence its quite optimized for best learning and comprehension outcome.</description>
    </item>
    
  </channel>
</rss>
