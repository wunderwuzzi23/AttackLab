<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>zombAI on Embrace The Red</title>
    <link>https://embracethered.com/blog/tags/zombai/</link>
    <description>Recent content in zombAI on Embrace The Red</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>(c) WUNDERWUZZI 2018-2024</copyright>
    <lastBuildDate>Mon, 23 Dec 2024 16:20:53 -0800</lastBuildDate><atom:link href="https://embracethered.com/blog/tags/zombai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Trust No AI: Prompt Injection Along the CIA Security Triad Paper</title>
      <link>https://embracethered.com/blog/posts/2024/trust-no-ai-prompt-injection-along-the-cia-security-triad-paper/</link>
      <pubDate>Mon, 23 Dec 2024 16:20:53 -0800</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2024/trust-no-ai-prompt-injection-along-the-cia-security-triad-paper/</guid>
      <description>Happy to share that I authored the paper &amp;ldquo;Trust No AI: Prompt Injection Along The CIA Security Triad&amp;rdquo;, based on research conducted over the past 18 months.
You can download it from arxiv.
The paper examines how prompt injection attacks compromise Confidentiality, Integrity, and Availability (CIA) of AI systems, with real-world examples targeting vendors like OpenAI, Google, Anthropic and Microsoft.
It summarizes and references many of the prompt injection examples I explained on this blog, and I hope this research helps bridge the gap between traditional cybersecurity practices and AI research, fostering stronger defenses against these emerging threats.</description>
    </item>
    
    <item>
      <title>ZombAIs: From Prompt Injection to C2 with Claude Computer Use</title>
      <link>https://embracethered.com/blog/posts/2024/claude-computer-use-c2-the-zombais-are-coming/</link>
      <pubDate>Thu, 24 Oct 2024 17:00:57 -0700</pubDate>
      
      <guid>https://embracethered.com/blog/posts/2024/claude-computer-use-c2-the-zombais-are-coming/</guid>
      <description>A few days ago, Anthropic released Claude Computer Use, which is a model + code that allows Claude to control a computer. It takes screenshots to make decisions, can run bash commands and so forth.
It&amp;rsquo;s cool, but obviously very dangerous because of prompt injection. Claude Computer Use enables AI to run commands on machines autonomously, posing severe risks if exploited via prompt injection.

Disclaimer So, first a disclaimer: Claude Computer Use is a Beta Feature and what you are going to see is a fundamental design problem in state-of-the-art LLM-powered Applications and Agents.</description>
    </item>
    
  </channel>
</rss>
